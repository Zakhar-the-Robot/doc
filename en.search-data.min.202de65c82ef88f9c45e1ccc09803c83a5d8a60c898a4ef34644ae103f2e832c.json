[{"id":0,"href":"/doc/docs/systems/brain/ros_install/","title":"Ros Install","section":"Brain","content":" ROS instalation # At the time of summer 2020 there is no way to install noetic on Raspberry Pi OS. That\u0026rsquo;s why we will build it manually\nROS Noetic build # Step 1 â€” Set up ROS Noetic repo on Raspberry Pi 4 # 1 sudo sh -c \u0026#39;echo \u0026#34;deb http://packages.ros.org/ros/ubuntu buster main\u0026#34; \u0026gt; /etc/apt/sources.list.d/ros-noetic.list\u0026#39; Step 2 â€” Add official ROS key # 1 sudo apt-key adv --keyserver \u0026#39;hkp://keyserver.ubuntu.com:80\u0026#39; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 Step 3 â€” Pull all meta info of ROS Noetic packages # 1 sudo apt update Step 4 â€” Install build dependencies on Raspberry Pi 4 # 1 sudo apt-get install -y python-rosdep python-rosinstall-generator python-wstool python-rosinstall build-essential cmake Step 5 â€” Set up ROS Noetic dependency sources/repos # 1 2 sudo rosdep init rosdep update Step 6 â€” Fetch \u0026amp; Install ROS Noetic dependencies # 1 2 3 4 5 mkdir ~/ros_catkin_ws cd ~/ros_catkin_ws rosinstall_generator ros_comm --rosdistro noetic --deps --wet-only --tar \u0026gt; noetic-ros_comm-wet.rosinstall wstool init src noetic-ros_comm-wet.rosinstall rosdep install -y --from-paths src --ignore-src --rosdistro noetic -r --os=debian:buster Step 7 â€” Compiling Noetic packages on Raspberry Pi 4 # 1 sudo src/catkin/bin/catkin_make_isolated --install -DCMAKE_BUILD_TYPE=Release --install-space /opt/ros/noetic -j1 -DPYTHON_EXECUTABLE=/usr/bin/python3 Done! # As a source of this manual was used an article:\nHow to Install ROS Noetic on Raspberry Pi 4 - VarHowto\n"},{"id":1,"href":"/doc/for_developers/","title":"For Developers","section":"Main","content":" For Developers # The project is ambitious, and I cannot move it that fast as I want to. If you are as interested in robotics as I am, let\u0026rsquo;s try to work together. I\u0026rsquo;m confident that we will develop something unique.\nThe project covers many different areas and programming languages, including:\n3D modeling (for simulation) 3D printing (for the robot itself) C / C ++ development (embedded: Arduino, ESP32, STM32; hi-level: Linux, Robot Operating System - ROS) Computer vision (image recognition, especially for indoor navigation) Hardware design (robot modules) Python development (Robot Operating System - ROS) Please look at the list of repositories and active projects below, see the issues, and take something if you want. If you want to participate but do not know where to start, create an issue in this repository, and we will figure this out.\nAny volunteer participation will be appreciated!\n"},{"id":2,"href":"/doc/docs/systems/brain/","title":"Brain","section":"Systems and Components","content":"\nSoftware for Zakhar\u0026rsquo;s brain. The \u0026ldquo;soul\u0026rdquo; of the robot.\nThe part is represented by 3 sub-repositories:\nzakharos_core - set of ROS-packages with main programs (using it you can run the robot\u0026rsquo;s mind) zakhar_pycore - Python modules provides interaction with the hardware zakhar_service - repo for service, debugging and testing Requirements # Hardware # Raspberry Pi \u0026gt;= 2 Gb RAM (or compatible platform) Compatible to the following I2C-devices: an-dr/zakhar-face-module: Zakhar\u0026rsquo;s part which is responsible for facial expressions an-dr/zakhar_sensors: Sensors implementation for the Zakhar Project an-dr/zakhar_platform: Controlled from i2c and uart moving platform for zakhar Software # ROS1 noetic (how to install) Python 3.7 or newer Python packages from requirements.txt Dev-Software # For the development it is recommended to use VSCode with installed recomended extensions on the Host. As for the Target it is recommended to use Raspberry Pi 4 with 2Gb and more of RAM\nSchematic # "},{"id":3,"href":"/doc/docs/systems/io_face/","title":"IO: Face Unit","section":"Systems and Components","content":" IO: Face Unit # The Face unit consists of two modules:\nESP-WROVER-KIT_V4_1 TJA-1050 CAN driver module The Unit can display a set of face expression by a command via the qCAN protocol. Each facial expression is defined by a jpg file:\n(see lib_zakhar_faces for the sources)\nCommunication # Protocol: qCAN 0.2.0, standard CAN frame Address: 0x4 Commands # Each command should consists of a single byte\nExpression Command code Anger 0x32 Blink 0x31 Calm 0x30 Pleasure 0x33 Sadness 0x34 Schematic # "},{"id":4,"href":"/doc/docs/systems/io_sensors/","title":"IO: Sensor Unit","section":"Systems and Components","content":" IO: Sensor Unit # A module collecting data from sensors. Periodically sends the data to the network.\nThe unit consists of:\n1x - Nucleo F411RE 3x - HC-SR04 module 1x - KY-018 photoresistor module 1x - MCP2515 CAN bus module Schematic # Communication # CAN bus\nProtocol: qCAN 0.2.0, standard CAN frame Address: 0x4 Serial\nSpeed: 115200 BPS Data Message # The unit sends a data message with sensor data every 100 ms.\nMessage Type: 0x1 (Data Message) Message content:\nField Value MSG ID 0x401 DATA0 HC-SR04 Left: distance - 0..200 cm DATA1 HC-SR04 Center: distance - 0..200 cm DATA2 HC-SR04 Right: distance - 0..200 cm DATA3 KY-018: Light value - High 4 bits DATA4 KY-018: Light value - Low 8 bits "},{"id":5,"href":"/doc/docs/systems/motion_wheels/","title":"Motion: Wheeled Platform","section":"Systems and Components","content":" Motion: Wheeled Platform # Zakhar moving platform equipped with an LED indication and an MPU module (GY-91).\nThe unit consists of:\nESP32 DevKit V1 - 36 pins GY-91 - MPU module HW-021 TJA1050 - CAN-bus driver Red-Green LED module Schematic # Communication # Bluetooth Serial\nDevice Name: Zakhar: Wheels PIN: 1234 CAN bus\nProtocol: qCAN 0.2.0, standard CAN frame Address: 0x2 Serial\nSpeed: 115200 BPS Commands # Each command should consists of a single byte (DATA0 of the CAN frame) and an optional argument (DATA1).\nAction Command Code Argument 0 [CAN DATA0] [CAN DATA1] FORWARD 0x77 BACKWARD 0x73 LEFT 0x61 Angle: 0x0..FF RIGHT 0x64 Angle: 0x0..FF SHIVER 0x71 STOP 0x20, 0xA0 SPEED0 0x30 SPEED1 0x31 SPEED2 0x32 SPEED3 0x33 MPU_CALIBRATE 0x63 SET_ARG_TO_30 0x23 TEST 0x74 Commands can be sent through the Serial interface using keyboard keys\nAction Keyboard Key FORWARD w BACKWARD s LEFT a RIGHT d SHIVER q STOP Space SPEED0 0 SPEED1 1 SPEED2 2 SPEED3 3 MPU_CALIBRATE c SET_ARG_TO_30 # TEST t "},{"id":6,"href":"/doc/docs/communication-protocols/canbus/","title":"qCAN","section":"Communication Protocols","content":" qCAN - a simple CAN protocol # qCAN (\u0026ldquo;kwÉª-kÃ¦n\u0026rdquo; or \u0026ldquo;kju-kÃ¦n\u0026rdquo; ) is a standard based on the CAN protocol. The main goal of the standard is to provide a minimalistic but efficient robotic communication protocol for fast development and simple debugging.\nqCAN extends bare CAN with the following features:\nEach device sends periodically a message indicating that the device is accessible Each message contains data about Source and Target devices CAN frame is a message one of the following types: ðŸ”µ Data - e.g. sensor data ðŸ”´ Command ðŸŸ¡ Presence - each node says to the network that the node is connected Data messages can be sent to the entire CAN network or to a specific device.\nCommands can be send similarly to all devices or a particular device.\nPresence messages must be sent at least once in 3 seconds by each device and can be addressed only to the entire CAN network.\nBase CAN configuration:\nBitrate: 125 kbits/s ID: 11 bits (standard mode) / 29 bits (extended mode) Addressing and Message Descriptor # Each device in the network has its unique Device ID. For the Standard Mode each device can have ID from 1 to 7, for the Extended Mode from 1 to 254.\nThe ID field of the CAN frame is used to describe the message. The descriptor contains:\nDevice ID of the sender Device ID of the target (0 for broadcasting) Message Type This information is mapped in the ID bits in the way allowing easy reading in HEX.\nOn the picture bellow you can see a Standard CAN frame and a qCAN ID structure\nAn Extended CAN frame allows qCAN to put more information into the ID field:\nMessage Types # Msg Type (extended) Name Description 0x0 Presence Message Used for presence declaration each 3 seconds (see details bellow). 0x1\u0026hellip;0x15 (0x255) DeviceData Device specific data defined by each device. 0xF (0xFF) Command Command format is different for each device, but using this data ID all nodes in the network can understand that this message is an input for a particular node. Examples of Message IDs:\n0x200 - a Presence message of the device with ID 0x2 0x52F - a Command message of the device 0x5 to 0x2 0x701 - a Data message of the device 0x7 for everybody 0xAA00000 - a Presence message of the device with ID 0xAA 0x01020FF - a Command message of the device 0x1 to 0x2 0x0C00001 - a Data message of the device 0xC for everybody Presence Messages # A device is online if it declares its presence at least once per 3 seconds.\nTo declare being online the device should send a CAN frame with following content:\nIdentifier: Source ID: ID of the device declaring the presence Target ID: 0 - broadcast message Message Type: 0x0 - presence message Data: Data0: qCAN Standard Major Version Data1: qCAN Standard Minor Version Data2: qCAN Standard Patch Version Versioning # Note: Until version 1.0.0 this section can be violated\nThe version consists of 3 numbers: Major.Minor.Patch (e.g. 2.3.9)\nAll devices using the same Major should be able to interact with other devices at least partly All devices using the same Minor should be able to fully interact with each other and have to have the same feature set Compatible libraries # Libraries bellow are developed inside the Zakhar project and support ZakharCAN.\nArduino: https://github.com/Zakhar-the-Robot/lib_arduino_canbus ESP-IDF: https://github.com/Zakhar-the-Robot/lib_espidf_canbus STM32: https://github.com/Zakhar-the-Robot/lib_stm32_canbus "},{"id":7,"href":"/doc/docs/systems/","title":"Systems and Components","section":"Docs","content":" Systems and Components # Zakhar consists of Units. Each Unit is a separate device with specific function.\nThe Units are designed to communicate with each other though a CAN-bus network. Zakhar has its own simple protocol qCAN built on top of bare CANbus.\nEach Unit represents a qCAN device with its unique DeviceID. Since it is possible to have two DeviceID on a single Unit we will use a term Node. Node is an qCAN-compatible CANbus device with a unique DeviceID.\nTechnically all Nodes can send and receive data and commands, but only one (Brain) is developed to perform as the Main Node. Other Nodes can be considered as Secondary ones. The Main Node differs of Secondary Nodes by possibility of command sending. Secondary Nodes can only receive commands and send data.\nSystems # All Units are split into Systems. A System is a group of Units serving a specific purpose. There are 4 Systems. Here is the full list and operating areas of each System:\nBrain System Processing of data from Secondary Nodes Decision making Control IO (In/Out) System Collecting data from sensors (In) Interacting with the User: sound, video, light, etc. (Out) Motion System Physical interactions Movements Diagnostics and Development (DnD) System Collecting of technical information for diagnostics Technical support for the development - OTA controller updates, etc. Units # Here is the full list of Zakhar Units:\nBrain System Brain Unit IO (In/Out) System Face Unit Sensor Unit (Sensors) Motion System Wheeled Platform Unit Diagnostics and Development (DnD) System CAN Tool Unit The main Node is the Brain Unit. Others are Secondary. Each Secondary periodically sends a special message so the Main Node knows that the Secondary is still connected to the network.\nAs it was told each Node has a unique DeviceID:\nMessage Content # WIP\n"}]